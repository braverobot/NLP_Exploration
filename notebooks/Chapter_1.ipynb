{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f3f3b17-eb39-4f68-9399-75b9e958b5bd",
   "metadata": {},
   "source": [
    "# Natural Language Processors with Transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678ea752-8eb4-48cb-9d23-50f0cd221b5e",
   "metadata": {},
   "source": [
    "## Text Classification- Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffe5732e-5ed6-482b-99b5-c75b547687c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to use Hugging Face Transformers\"\n",
    "# The pipeline function from the transformers library is designed to make it easier to use various\n",
    "#  Natural Language Processing (NLP) tasks. When you create a pipeline, you specify two key\n",
    "#  arguments: the task you want to perform, and optionally, the model you want to use for that task. \n",
    "# Start by importing pipelines from transformer\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8816449f-c9d9-488d-8a18-4feb5089c17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets make a positive sentiment\n",
    "text = \"\"\"Dear Esteemed Lunar Vanguard Team,\n",
    "\n",
    "I recently acquired the Multi-Functional Gadgetron from your lunar store and I'm genuinely impressed! The design is remarkably innovative, demonstrating the exceptional creativity and technological prowess of humans. Its diverse functions have been immensely helpful in my intergalactic travels. I did notice a slight hiccup with the interstellar compatibility mode under different gravitational conditions, but it's a minor issue in the grand scheme. Also, a suggestion for future iterations - including more galactic language options in the manual would be a delightful touch for us extraterrestrial users. Overall, it's a fantastic product that embodies the spirit of human ingenuity. Eagerly awaiting future innovations!\n",
    "\n",
    "Warm regards,\n",
    "Zarlox from Zeta Reticuli\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9b4cc44-99e0-492d-a83b-a2e080bd5144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put together some text that you want evaluated to see if its positive or negative...\n",
    "text2 = \"\"\"Dear Terran Outpost,\n",
    "\n",
    "I am writing to express my experience with the Multi-Functional Gadgetron I purchased during my last visit to your lunar establishment. Firstly, I must commend the innovative design and versatile functionality; it truly showcases the ingenuity of human engineering. However, I encountered some challenges with the interstellar compatibility mode. The device struggles to adapt to the gravitational variances of my home planet, leading to occasional malfunctions in its holographic display. Additionally, the user manual, while comprehensive, lacks translations in common galactic languages, which made initial setup quite perplexing. I appreciate the effort to accommodate diverse species, but these improvements would greatly enhance usability for us non-Terrans. Looking forward to the updated version.\n",
    "\n",
    "Sincerely,\n",
    "Zarlox from Zeta Reticuli\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "710bfee5-cb85-41d9-993f-e6c255c31165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm going to use pandas to look at dataframes that I get back from the classifier, so i'll import it heref\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86f7d82b-1d35-45f5-a65d-75cbc6910303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we want to instantiate a pipeline by calling the `pipelines()` function\n",
    "#\n",
    "# When you pass \"text-classification\" as an argument, the pipeline function creates a pipeline for\n",
    "#  classifying text. This includes loading a model that has been trained on a text classification\n",
    "#  task, along with all necessary preprocessing and postprocessing steps.\n",
    "#\n",
    "# Note: it defaults to distilbert for the model, but just use it so you don't get a warning msg\n",
    "#  This is a model that’s been trained specifically for sentiment analysis (a type of text \n",
    "#  classification) on English text.\n",
    "# \n",
    "classifier = pipeline(\"text-classification\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a7a58e0-db5c-4561-9d36-62d44c561f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9942922592163086}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = classifier(\"text\")\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59cd5001-3596-4eb2-948a-5e0f28679c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.994292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label     score\n",
       "0  POSITIVE  0.994292"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets make the array look nicer with dataframes in pandas\n",
    "pd.DataFrame(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246f5931-b843-48cf-85f9-af72d24d6136",
   "metadata": {},
   "source": [
    "**As you can see the label shows up as positive, and the score is almost 1. Very positive!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07351507-0502-488d-905d-848e8599459b",
   "metadata": {},
   "source": [
    "## Named Entity Recognition (NER)\n",
    "**Named Entities are Persons / Places / Products / People. Basically Real world objects. NER helps extract them from the text**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e556d85-5b37-4a2c-9773-77b3954acc89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# We can employ NER by instantiating a pipeline and then feeding our customer review to it\n",
    "# If no model is supplied, it defaults to \"dbmdz/bert-large-cased-finetuned-conll03-english\"\n",
    "ner_tagger = pipeline(\"ner\", aggregation_strategy=\"simple\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7a0dc61-6424-4f1f-995f-222bb8ff9fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_group</th>\n",
       "      <th>score</th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.994586</td>\n",
       "      <td>Lunar Vanguard Team</td>\n",
       "      <td>14</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.818788</td>\n",
       "      <td>Multi - Functional Gadgetron</td>\n",
       "      <td>60</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PER</td>\n",
       "      <td>0.668797</td>\n",
       "      <td>Zar</td>\n",
       "      <td>776</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.505405</td>\n",
       "      <td>##lox</td>\n",
       "      <td>779</td>\n",
       "      <td>782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.953664</td>\n",
       "      <td>Zeta Reticuli</td>\n",
       "      <td>788</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  entity_group     score                          word  start  end\n",
       "0          ORG  0.994586           Lunar Vanguard Team     14   33\n",
       "1         MISC  0.818788  Multi - Functional Gadgetron     60   86\n",
       "2          PER  0.668797                           Zar    776  779\n",
       "3          ORG  0.505405                         ##lox    779  782\n",
       "4          ORG  0.953664                 Zeta Reticuli    788  801"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ner = ner_tagger(text)\n",
    "pd.DataFrame(output_ner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84a8d31-e491-4ec8-bad3-17b7a1fac95a",
   "metadata": {},
   "source": [
    "**As you can see it was able to pick out the important bits of the text**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77b8786-bdca-4a8a-b4ca-a7b0cee2ceed",
   "metadata": {},
   "source": [
    "## Question Answering\n",
    "**This is pretty cool. You can pass your text to the model as an argument 'context', and then supply a question that you would like the model to try to derive from the context.**\n",
    "**This is using what is known as _extractive question answering_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4740f147-a9a5-4491-bcfc-7b2b76620790",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a77798f0-a2bd-480d-8d4a-fe6bdd309b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What does the customer want?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63e1c1fd-3754-4095-8f90-826a5cb89ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = reader(question=question, context=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c6ac7e7-586a-4912-b6e6-f36543aa915c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.04932</td>\n",
       "      <td>541</td>\n",
       "      <td>571</td>\n",
       "      <td>more galactic language options</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     score  start  end                          answer\n",
       "0  0.04932    541  571  more galactic language options"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.DataFrame([outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ac6655-5077-4ffc-a822-3db5bbcb937d",
   "metadata": {},
   "source": [
    "## Summarization\n",
    "**Take all the text and generate a shorter version of it**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13fcb85f-f732-4b4b-9039-f6703da9d69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The design is remarkably innovative, demonstrating the exceptional creativity and technological prowess of humans. I did notice a slight hiccup with the interstellar compatibility mode under different gravitational conditions. Overall, it's a fantastic product that embodies the spirit of human ingenuity. Eagerly awaiting\n"
     ]
    }
   ],
   "source": [
    "# If No model is supplied, defaulted to sshleifer/distilbart-cnn-12-6\n",
    "# In this example you'll see that we can tweak the output post processing (ie by using max length and cleanup tokens etc.\n",
    "summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\n",
    "outputs = summarizer(text, max_length=56, clean_up_tokenization_spaces=True)\n",
    "print(outputs[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf5070a-38bc-45d4-80a6-972f143dd6ed",
   "metadata": {},
   "source": [
    "## Translation\n",
    "**Lets use a translation pipeline to translate English to Russian**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e214ffb-3281-43fa-9236-404ac9751ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the pipeline with the specific translators you want. i'll choose both german and russian\n",
    "german_translator = pipeline(\"translation_en_to_de\", model=\"Helsinki-NLP/opus-mt-en-de\")\n",
    "ru_translator = pipeline(\"translation_en_to_ru\", model=\"Helsinki-NLP/opus-mt-en-ru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2d76608-fb56-48bc-8d09-cdd064cf4185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liebe Esteemed Lunar Vanguard Team, Ich habe vor kurzem die Multi-Functional Gadgetron aus Ihrem lunar Store erworben und ich bin wirklich beeindruckt! Das Design ist bemerkenswert innovativ, zeigt die außergewöhnliche Kreativität und technologische Leistungsfähigkeit der Menschen. Seine vielfältigen Funktionen waren enorm hilfreich bei meinen intergalaktischen Reisen. Ich habe eine leichte Schluckauf mit dem interstellaren Kompatibilitätsmodus unter verschiedenen Gravitationsbedingungen bemerkt, aber es ist ein kleines Problem in der großen Schema. Auch ein Vorschlag für zukünftige Iterationen - einschließlich mehr galaktische Sprachoptionen im Handbuch wäre eine herrliche Berührung für uns außerirdische Benutzer. Insgesamt ist es ein fantastisches Produkt, das den Geist der menschlichen Einfallsreichtum verkörpert. Eifrig auf zukünftige Innovationen warten! Warme Grüße, Zarlox von Zeta Reticuli\n"
     ]
    }
   ],
   "source": [
    "# now create outputs based on our text, and a few of the postprocessor arguments (cleanup and min len)\n",
    "outputs = german_translator(text, clean_up_tokenization_spaces=True, min_length=100)\n",
    "print(outputs[0]['translation_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cd28f6-c318-4d90-aaa6-7516bb256cd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12251829-761d-4f80-9768-cbd626e4bde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Дорогая Эстемед Лунар Вангар, я недавно приобрела многофункциональное Гадгетрон из вашего лунного магазина и я действительно впечатлена! Этот дизайн удивительно новаторский, демонстрирующий исключительный творческий и технологический талант людей. Его разнообразные функции были чрезвычайно полезны в моих межгалактических путешествиях. Я заметила небольшую икотику с межзвездным режимом совместимости при различных гравитационных условиях, но это небольшая проблема в великой схеме. Кроме того, предложение о будущих итерациях - включая более галактические варианты в руководстве было бы восхитительным прикосновением для внеземных пользователей. В целом, это фантастический продукт, который воплощает дух человеческой изобретательности. Эгерли ожидает будущих инноваций.\n"
     ]
    }
   ],
   "source": [
    "# and now lets do it for russian!\n",
    "outputs = ru_translator(text, clean_up_tokenization_spaces=True, min_length=100)\n",
    "print(outputs[0]['translation_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4859a2e3-0ac5-4111-a0b9-676a77a0b40b",
   "metadata": {},
   "source": [
    "## Text Generation for a response\n",
    "**You can use transformers pipeline() to create a response to a message as well!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9b6ccd1-9f45-4d20-8ac0-e2037975b999",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "/Users/heartwood/.pyenv/versions/NLP/lib/python3.11/site-packages/transformers/generation/utils.py:1281: UserWarning: Input length of input_ids is 214, but `max_length` is set to 200. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# If no model is selected, it defaults to gpt2\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "response = \"\"\"Dear Zarlox,\n",
    "\n",
    "Thank you for your glowing review of the Gadgetron! The Lunar Vanguard Team is excited to incorporate your suggestions for improved interstellar compatibility and broader language support in our next update.\n",
    "\n",
    "Best regards,\n",
    "The Lunar Vanguard Team\"\"\"\n",
    "\n",
    "\n",
    "prompt = text + \"\\nTerra Nova Customer Service Response:\\n\" + response\n",
    "outputs = generator(prompt, max_length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4ea4733-f55e-4a50-91b9-b91b8a54bdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear Esteemed Lunar Vanguard Team,\n",
      "\n",
      "I recently acquired the Multi-Functional Gadgetron from your lunar store and I'm genuinely impressed! The design is remarkably innovative, demonstrating the exceptional creativity and technological prowess of humans. Its diverse functions have been immensely helpful in my intergalactic travels. I did notice a slight hiccup with the interstellar compatibility mode under different gravitational conditions, but it's a minor issue in the grand scheme. Also, a suggestion for future iterations - including more galactic language options in the manual would be a delightful touch for us extraterrestrial users. Overall, it's a fantastic product that embodies the spirit of human ingenuity. Eagerly awaiting future innovations!\n",
      "\n",
      "Warm regards,\n",
      "Zarlox from Zeta Reticuli\n",
      "Terra Nova Customer Service Response:\n",
      "Dear Zarlox,\n",
      "\n",
      "Thank you for your glowing review of the Gadgetron! The Lunar Vanguard Team is excited to incorporate your suggestions for improved interstellar compatibility and broader language support in our next update.\n",
      "\n",
      "Best regards,\n",
      "The Lunar Vanguard Team\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(outputs[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d40946-493e-449f-b2ff-4d74174231fb",
   "metadata": {},
   "source": [
    "## Interesting Links\n",
    "* HF Hub:                       https://oreil.ly/zLK11\n",
    "* HF Tokenizers & Transformers: https://oreil.ly/Z79jF\n",
    "* HF Datasets:                  https://oreil.ly/959YT\n",
    "* HF Accelerate:                https://oreil.ly/iRfDe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2761c89-b9a8-4634-a032-f71e0bc1a397",
   "metadata": {},
   "source": [
    "# Conclusion- The main challenges with transformers\n",
    "1. **Language**- NLP Is dominated with english language\n",
    "2. **Data availability**- Transfer learning can reduce the amount of labeled training data, but its still a lot compared to how much a human needs to perform a task\n",
    "3. **Working with long documents**- self-attention works well on paragraph-long texts, but it gets harder with whole documents\n",
    "4. **Opacity**- Its hard to unravel 'why' the pipeline makes the predictions it does\n",
    "5. **Bias**- The models are trained on the internet, and the internet is a bias effing place for real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49bbe3d-40aa-4893-ad42-b4354b5e394f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.11 (NLP)",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
